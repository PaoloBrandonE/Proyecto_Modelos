import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
import numpy as np
from scipy.stats import zscore

# Cargar el conjunto de datos
data = pd.read_csv('/content/data25k.csv')

# Limpiar la columna 'Price' (remover comas y convertir a numérico)
data['Price'] = data['Price'].str.replace(',', '').astype(float)

# Limpiar la columna 'Mileage' (remover ' km' y convertir a numérico)
data['Mileage'] = data['Mileage'].str.replace(' km', '', regex=True).astype(float)


# Limpiar la columna 'Engine volume' (extraer solo valores numéricos antes de texto adicional)
data['Engine volume'] = data['Engine volume'].str.extract(r'(\d+\.?\d*)').astype(float)

# Tratar valores faltantes o inconsistentes en las columnas relevantes
# Reemplazar valores faltantes ('-') con NaN para una mejor gestión
data.replace('-', pd.NA, inplace=True)

# Eliminar filas con valores faltantes en columnas críticas
data.dropna(subset=['Price', 'Mileage', 'Cylinders', 'Engine volume'], inplace=True)

# Detectar outliers en la columna 'Price' utilizando el z-score
data['z_score'] = zscore(data['Price'])  # Calcular z-scores para los precios
outliers = data[np.abs(data['z_score']) > 3]  # Identificar valores con z-score mayor a 3
print(f"Cantidad de outliers detectados: {len(outliers)}")
print(outliers[['Price', 'z_score']])  # Mostrar precios y sus z-scores

# Seleccionar las características y la variable objetivo
X = data[['Manufacturer', 'Prod. year', 'Category', 
          'Mileage', 'Cylinders']]
y = data['Price']

# Ajustar las columnas categóricas a las que realmente existen en el dataset
categorical_features = ['Manufacturer', 'Category']  # Eliminamos 'Fuel type' si no está presente

# Codificar variables categóricas con OneHotEncoder
one_hot = OneHotEncoder(drop='first', sparse_output=False)

# Crear un transformador para las variables categóricas
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', one_hot, categorical_features)
    ], remainder='passthrough'  # Mantiene las variables numéricas
)

# Transformar las características
X_transformed = preprocessor.fit_transform(X)

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.25, random_state=42)

# Ajustar el modelo de regresión lineal
model = LinearRegression()
model.fit(X_train, y_train)

# Hacer predicciones
y_pred = model.predict(X_test)

# Calcular métricas de evaluación
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
accuracy = np.sum(np.abs((y_test - y_pred) / y_test) <= 0.10) / len(y_test) * 100

# Imprimir resultados
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"R-squared (R2): {r2:.2f}")
print(f"Mean Absolute Percentage Error (MAPE): {mape:.2f}%")
print(f"Accuracy (predicciones dentro del ±10%): {accuracy:.2f}%")

from sklearn.ensemble import RandomForestRegressor

# Entrenar un modelo de Random Forest
rf_model = RandomForestRegressor(random_state=42)
rf_model.fit(X_train, y_train)

# Predicciones y evaluación
y_pred_rf = rf_model.predict(X_test)
mse_rf = mean_squared_error(y_test, y_pred_rf)
r2_rf = r2_score(y_test, y_pred_rf)
accuracy_rf = np.sum(np.abs((y_test - y_pred_rf) / y_test) <= 0.10) / len(y_test) * 100

print(f"Random Forest MSE: {mse_rf:.2f}")
print(f"Random Forest R2: {r2_rf:.2f}")
print(f"Random Forest Accuracy (±10%): {accuracy_rf:.2f}%")



import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

# Cargar el conjunto de datos
data = pd.read_csv('/content/data25k.csv')

# Limpiar la columna 'Price' (remover comas y convertir a numérico)
data['Price'] = data['Price'].str.replace(',', '').astype(float)

# Limpiar la columna 'Mileage' (remover ' km' y convertir a numérico)
data['Mileage'] = data['Mileage'].str.replace(' km', '', regex=True).astype(float)


# Limpiar la columna 'Engine volume' (extraer solo valores numéricos antes de texto adicional)
data['Engine volume'] = data['Engine volume'].str.extract(r'(\d+\.?\d*)').astype(float)

# Tratar valores faltantes o inconsistentes en las columnas relevantes
# Reemplazar valores faltantes ('-') con NaN para una mejor gestión
data.replace('-', pd.NA, inplace=True)

# Eliminar filas con valores faltantes en columnas críticas
data.dropna(subset=['Price', 'Mileage', 'Cylinders', 'Engine volume'], inplace=True)

# Seleccionar las características y la variable objetivo
X = data[['Manufacturer', 'Prod. year', 'Category',
          'Fuel type', 'Engine volume', 'Mileage', 'Cylinders']]
y = data['Price']

# Codificar variables categóricas con números enteros
# Convertir las variables categóricas en valores numéricos utilizando 'category' y 'cat.codes'
categorical_features = ['Manufacturer', 'Category', 'Fuel type']

for feature in categorical_features:
    X.loc[:, feature] = X[feature].astype('category').cat.codes  # Usando .loc[] para evitar el warning

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)

# Ajustar el modelo de regresión lineal
model = LinearRegression()
model.fit(X_train, y_train)

# Hacer predicciones
y_pred = model.predict(X_test)

# Evaluar el modelo
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# Calcular el MAPE (Mean Absolute Percentage Error)
mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100

# Calcular porcentaje de predicciones acertadas (±10% del valor real)
tolerance = 0.10
accuracy = np.sum(np.abs((y_test - y_pred) / y_test) <= tolerance) / len(y_test) * 100

# Mostrar resultados
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"R-squared (R2): {r2:.2f}")
print(f"Mean Absolute Percentage Error (MAPE): {mape:.2f}%")
print(f"Accuracy (predicciones dentro del ±10%): {accuracy:.2f}%")
print("****************************************************************")




